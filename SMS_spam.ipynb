{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn import svm,metrics\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df = pd.read_table(\"C:/Users/Swati/Desktop/spam filter/SMSSpamCollection.txt\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Have a look at the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "0    5572 non-null object\n",
      "1    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 43.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#get some onfo about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the target variable\n",
    "y = df[0]\n",
    "\n",
    "# Display the class distribution\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the class labels as numbers\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the SMS message data\n",
    "raw_text = df[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Normalization\n",
    "\n",
    "    - Replace email addresses with 'emailaddr'\n",
    "    - Replace URLs with 'httpaddr'\n",
    "    - Replace money symbols with 'moneysymb'\n",
    "    - Replace phone numbers with 'phonenumbr'\n",
    "    - Replace numbers with 'numbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace email addresses with 'emailaddr'\n",
    "processed = raw_text.str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b','emailaddr')\n",
    "\n",
    "# Replace URLs with 'httpaddr'\n",
    "processed = processed.str.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)','httpaddr')\n",
    "\n",
    "# Replace money symbols with 'moneysymb'\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace phone numbers with 'phonenumbr'\n",
    "processed = processed.str.replace(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b','phonenumbr')\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n",
    "\n",
    "# Remove punctuation\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n",
    "\n",
    "# Lowercase the corpus\n",
    "processed = processed.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Removing Stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Remove all stop words\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in set(stop_words))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove word stems using a Porter stemmer\n",
    "porter = nltk.PorterStemmer()\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    porter.stem(term) for term in x.split())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets combine this into one handy function which takes into string and returns processed string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(messy_string):\n",
    "    assert(type(messy_string) == str)\n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', messy_string)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',cleaned)\n",
    "    cleaned = re.sub(r'£|\\$', 'moneysymb', cleaned)\n",
    "    cleaned = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b','phonenumbr', cleaned)\n",
    "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check this function on one example :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'congratl numbr ticket hamilton nyc httpaddr worth moneysymbnumbr call phonenumbr send messag emailaddr get ticket'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"\"\"  ***** CONGRATlations **** You won 2 tIckETs to Hamilton in \n",
    "NYC http://www.hamiltonbroadway.com/J?NaIOl/event   wORtH over $500.00...CALL \n",
    "555-477-8914 or send message to: hamilton@freetix.com to get ticket !! !  \"\"\"\n",
    "\n",
    "preprocess_text(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "### Implementing the tf-idf statistic\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we're equipped to transform a corpus of text data into a matrix of numbers with one row per training example and one column per n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 36345)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a design matrix using an n-gram model and a tf-idf statistics\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_ngrams = vectorizer.fit_transform(processed)\n",
    "\n",
    "#Let's take a look at the dimensions of the X_ngrams matrix.\n",
    "X_ngrams.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using SVM (Support Vector Machine) which basically attempts to find hyperplane that best seperates the two classes. We'll use SVM with linear kernal because of large number of features in our training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the training and test sets using an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ngrams,\n",
    "    y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_enc\n",
    ")\n",
    "\n",
    "# Train SVM with a linear kernel on the training set\n",
    "clf = svm.LinearSVC(loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the F1 score\n",
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>spam</th>\n",
       "      <td>965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>19</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted     \n",
       "                 spam  ham\n",
       "actual spam       965    1\n",
       "       ham         19  130"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a confusion matrix\n",
    "pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, y_pred),\n",
    "    index=[['actual', 'actual'], ['spam', 'ham']],\n",
    "    columns=[['predicted', 'predicted'], ['spam', 'ham']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a function that takes message as input and tells us whether the message is spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_filter(message):\n",
    "    if clf.predict(vectorizer.transform([preprocess_text(message)])):\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'not spam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check this example on the above function.\n",
    "spam_filter(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not spam'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check another one :\n",
    "spam_filter('You have an interview tomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
